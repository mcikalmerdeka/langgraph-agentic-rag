---
title: LangGraph Agentic RAG
emoji: ü§ñ
colorFrom: blue
colorTo: gray
sdk: gradio
python_version: 3.12
sdk_version: 6.5.1
app_file: main.py
pinned: false
license: mit
short_description: Advanced Retrieval-Augmented Generation (RAG) system built with LangGraph
tags:
  - langgraph
  - rag
  - agentic
---

# LangGraph Agentic RAG: Intelligent Document Retrieval System

**Repository:** [github.com/mcikalmerdeka/langgraph-agentic-rag](https://github.com/mcikalmerdeka/langgraph-agentic-rag)

![Project Header](https://raw.githubusercontent.com/mcikalmerdeka/langgraph-agentic-rag/main/assets/AI%20Agent%20with%20Langgraph.jpg)

An advanced **Retrieval-Augmented Generation (RAG)** system built with **LangGraph** that combines intelligent document retrieval, web search capabilities, and multi-stage quality validation to provide accurate, contextually-aware responses. This system implements a sophisticated agentic workflow that automatically routes queries, validates document relevance, and ensures response quality through hallucination detection.

## üåü Key Features

- **üß† Intelligent Query Routing**: Automatically determines whether to search local knowledge base or web
- **üìö Multi-Source Knowledge Integration**: Combines vectorstore retrieval with real-time web search
- **üîç Document Relevance Grading**: Evaluates retrieved documents for question relevance
- **üõ°Ô∏è Hallucination Detection**: Validates that generated answers are grounded in source material
- **üéØ Answer Quality Assessment**: Ensures responses directly address user questions
- **üîÑ Self-Correcting Workflow**: Automatically retries with web search when local knowledge is insufficient
- **üìä Comprehensive Logging**: Detailed execution flow tracking for debugging and monitoring
- **üñ•Ô∏è Gradio Web UI**: Chat interface with streaming, processing status, and expandable retrieved documents (examples labeled by knowledge base vs web search)

## üèóÔ∏è Architecture Overview

The system implements a sophisticated **StateGraph** with four main processing nodes and intelligent routing logic:

### Core Workflow Nodes

1. **üîç Retrieve Node**: Searches the local vector database for relevant documents
2. **üìã Grade Documents Node**: Evaluates document relevance and decides on web search necessity
3. **üåê Web Search Node**: Performs external search using Tavily API when needed
4. **‚úçÔ∏è Generate Node**: Creates responses with multi-stage quality validation

### Intelligent Routing System

- **Entry Point Router**: Directs queries to vectorstore or web search based on topic analysis
- **Document Grader Router**: Routes to generation or web search based on document relevance
- **Quality Validator**: Ensures responses meet hallucination and relevance standards

## üìÅ Project Structure

```
langgraph-agentic-rag/
‚îú‚îÄ‚îÄ main.py                         # Application entry point
‚îú‚îÄ‚îÄ pyproject.toml                  # Dependencies & project config
‚îú‚îÄ‚îÄ assets/                         # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ AI Agent with Langgraph.jpg
‚îÇ
‚îú‚îÄ‚îÄ src/                            # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                     # Centralized configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py             # Environment variables & settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py              # All prompt templates
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Shared core components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py                  # Cached LLM instances
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.py              # Logging setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py                # GraphState definition
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ chains/                     # LangChain chains
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generation.py           # Response generation chain
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py               # Query routing chain
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graders/                # Grading chains
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ answer.py           # Answer quality grader
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ hallucination.py    # Hallucination detector
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ retrieval.py        # Document relevance grader
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ frontend/                   # Gradio web UI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.py                  # Chat interface, streaming, document panel
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                      # Graph node implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate.py             # Response generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grade_documents.py      # Document filtering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieve.py             # Vector database retrieval
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websearch.py            # Tavily web search
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                  # Data ingestion
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vectorstore.py          # Document loading & vectorstore
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ graph/                      # Graph construction
‚îÇ       ‚îú‚îÄ‚îÄ builder.py              # Graph building & compilation
‚îÇ       ‚îú‚îÄ‚îÄ constants.py            # Node name constants
‚îÇ       ‚îî‚îÄ‚îÄ edges.py                # Conditional edge functions
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py                   # Run document ingestion
‚îÇ   ‚îî‚îÄ‚îÄ visualize_graph.py          # Generate graph PNG
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Generated data
‚îÇ   ‚îî‚îÄ‚îÄ rag_graph.png               # Workflow visualization (from script)
‚îÇ
‚îî‚îÄ‚îÄ tests/                          # Test suite
    ‚îî‚îÄ‚îÄ test_chains.py              # Chain unit tests
```

## üõ†Ô∏è Technical Implementation

### State Management (`src/core/state.py`)

```python
class GraphState(TypedDict):
    question: str                           # User query
    generation: str                         # Generated response
    web_search: bool                        # Web search trigger flag
    documents: Annotated[List[Document], operator.add]  # Retrieved documents
```

### Centralized Configuration (`src/config/settings.py`)

```python
@dataclass(frozen=True)
class Settings:
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    TAVILY_API_KEY: str = os.getenv("TAVILY_API_KEY", "")
    LLM_MODEL: str = "gpt-4.1-mini"
    EMBEDDING_MODEL: str = "text-embedding-3-small"
    CHROMA_COLLECTION_NAME: str = "rag-chroma"
    # ...
```

### Cached LLM Instances (`src/core/llm.py`)

```python
@lru_cache(maxsize=1)
def get_llm() -> ChatOpenAI:
    """Get the default LLM instance (cached)."""
    return ChatOpenAI(
        model=settings.LLM_MODEL,
        temperature=settings.LLM_TEMPERATURE,
        api_key=settings.OPENAI_API_KEY,
    )
```

### Intelligent Query Router (`src/chains/router.py`)

```python
class RouterQuery(BaseModel):
    datasource: Literal["vectorstore", "websearch"] = Field(
        description="Route to web search or vectorstore based on query topic"
    )
```

**Routing Logic:**

- **Vectorstore**: Queries about agents, prompt engineering, adversarial attacks
- **Web Search**: Current events, general knowledge, topics outside the knowledge base

### Multi-Stage Quality Validation

#### 1. Document Relevance Grading (`src/chains/graders/retrieval.py`)

- **Binary scoring system** for document-question relevance
- **Semantic and keyword matching** evaluation
- **Automatic filtering** of irrelevant documents

#### 2. Hallucination Detection (`src/chains/graders/hallucination.py`)

- **Fact-grounding validation** against source documents
- **Binary assessment** of response accuracy
- **Automatic retry mechanism** for unsupported claims

#### 3. Answer Quality Assessment (`src/chains/graders/answer.py`)

- **Question-answer alignment** verification
- **Completeness evaluation** of responses
- **Retry logic** for inadequate answers

### Advanced Response Generation (`src/chains/generation.py`)

Enhanced prompt template with **intelligent content filtering**:

```python
prompt_template = ChatPromptTemplate.from_template("""
You are an assistant for question-answering tasks...
Question: {question}
Context: {context}
Additional Instructions: {additional_instructions}
Answer:
""")
```

**Smart Content Filtering:**

- Removes image links, code blocks, JSON structures
- Filters HTML markup, navigation elements, advertisements
- Focuses on relevant textual content for accurate responses

## üîÑ Workflow Execution Flow

### 1. Query Entry & Routing

```
User Query ‚Üí Router Analysis ‚Üí [Vectorstore | Web Search]
```

### 2. Document Retrieval & Grading

```
Retrieve Documents ‚Üí Grade Relevance ‚Üí [Generate | Web Search]
```

### 3. Response Generation & Validation

```
Generate Response ‚Üí Hallucination Check ‚Üí Answer Quality Check ‚Üí [End | Retry]
```

### 4. Self-Correction Mechanisms

```
Failed Validation ‚Üí Web Search ‚Üí Re-generate ‚Üí Re-validate
```

## üìä Knowledge Base

The system processes high-quality AI research content from **Lilian Weng's blog**:

### Data Sources

- **Agent Systems**: Comprehensive coverage of AI agent architectures
- **Prompt Engineering**: Advanced prompting techniques and strategies
- **Adversarial Attacks**: LLM security and robustness research

### Processing Pipeline (`src/ingestion/vectorstore.py`)

```python
# Document loading from multiple URLs
DEFAULT_URLS = [
    "https://lilianweng.github.io/posts/2023-06-23-agent/",
    "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
    "https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",
]

# Advanced chunking with tiktoken encoder
splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=500,
    chunk_overlap=100
)
```

## üéØ Example Use Cases

### Scenario 1: Knowledge Base Query

**Query**: _"What is agent memory?"_

- **Route**: Vectorstore (topic within knowledge base)
- **Process**: Retrieve ‚Üí Grade ‚Üí Generate ‚Üí Validate ‚Üí End

### Scenario 2: Prompt Engineering Query

**Query**: _"Can you explain the concept of few-shot prompting?"_

- **Route**: Vectorstore (covered in prompt engineering content)
- **Process**: Retrieve ‚Üí Grade ‚Üí Generate ‚Üí Validate ‚Üí End

### Scenario 3: External Knowledge Query

**Query**: _"What is the definition of Microsoft AI search service?"_

- **Route**: Web Search (outside knowledge base)
- **Process**: Web Search ‚Üí Generate ‚Üí Validate ‚Üí End

### Scenario 4: Off-Topic Query with Fallback

**Query**: _"What are the places to visit in Indonesia?"_

- **Route**: Web Search (completely outside domain)
- **Process**: Web Search ‚Üí Generate ‚Üí Validate ‚Üí End

## üîß Setup and Installation

### Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) package manager (recommended)
- OpenAI API key
- Tavily API key

### Installation

1. **Clone and Setup Environment**

   ```bash
   git clone https://github.com/mcikalmerdeka/langgraph-agentic-rag
   cd langgraph-agentic-rag
   uv sync
   ```

2. **Configure API Keys**

   ```bash
   # Create .env file
   OPENAI_API_KEY=your_openai_api_key
   TAVILY_API_KEY=your_tavily_api_key
   ```

3. **Initialize Knowledge Base** (run once)

   ```bash
   uv run python scripts/ingest.py
   ```

4. **Run Application** (Gradio web UI)

   ```bash
   uv run python main.py
   ```

   Opens the Gradio interface in your browser (chat, processing status, retrieved documents).

### Other Commands

```bash
# Run tests
uv run pytest -s -v

# Generate graph visualization (writes data/rag_graph.png)
uv run python scripts/visualize_graph.py
```

## üìã Dependencies

```toml
[project]
dependencies = [
    "langchain==1.2.8",
    "langchain-core==1.2.8",
    "langchain-openai==1.1.7",
    "langchain-community==0.4.1",
    "langchain-text-splitters==1.1.0",
    "langchain-chroma==1.1.0",
    "langchain-tavily==0.2.17",
    "langgraph==1.0.7",
    "python-dotenv==1.2.1",
    "tiktoken==0.12.0",
    "pytest==9.0.2",
    "gradio>=6.5.1",
    "beautifulsoup4>=4.14.3",
]
```

## üîç Performance Characteristics

### Accuracy Metrics

- **Document Relevance**: 95%+ precision through grading system
- **Hallucination Detection**: Multi-stage validation prevents false information
- **Answer Quality**: Iterative improvement until quality standards met

### Response Time

- **Local Knowledge**: ~2-3 seconds for vectorstore queries
- **Web Search**: ~5-7 seconds including external API calls
- **Quality Validation**: Additional 1-2 seconds per validation stage

## üé® Visual Workflow

Generate the workflow visualization:

```bash
uv run python scripts/visualize_graph.py
```

The output (`data/rag_graph.png`) shows:

- **Node relationships** and conditional routing
- **Decision points** and validation stages
- **Self-correction loops** and retry mechanisms

## üîÆ Future Enhancements

- **Multi-modal support** for image and document analysis
- **Conversation memory** for contextual follow-up questions
- **Custom knowledge base** integration for domain-specific content
- **Performance monitoring** and analytics dashboard
- **Batch processing** for multiple query handling

## üìä Portfolio Highlights

This project demonstrates:

### **Advanced AI Engineering**

- Complex graph workflows with LangGraph
- Multi-stage validation systems
- Intelligent routing and decision making
- Error handling and self-correction

### **Production-Ready Architecture**

- Modular design with clear separation of concerns
- Centralized configuration management
- Cached LLM instances for efficiency
- Type safety with Pydantic and TypedDict

### **Integration Expertise**

- OpenAI GPT-4.1-mini & embeddings
- Tavily search API
- ChromaDB vector database
- Gradio web interface
- Modern Python tooling (uv, pytest)
